INFO:	main:	Namespace(n_degree=30, n_head=2, n_layer=2, drop_out=0.3, reg=0.3, node_dim=32, time_dim=32, agg_method='attn', attn_mode='prod', uniform=True, new_node=False, time='time', disencomponents=None, data='ml-100k', samplerate=1.0, popnegsample=False, timepopnegsample=False, negsampleeval=1000, bs=600, n_epoch=3, lr=0.001, prefix='movielens100k', gpu=0, seed=42)
INFO:	TGSRec:	Aggregation uses attention model
INFO:	attention_model:	Using scaled prod attention
INFO:	attention_model:	Using scaled prod attention
INFO:	TGSRec:	Using time encoding
INFO:	trainer:	Model built successfully
INFO:	trainer:	TGRec(
  (node_hist_embed): Embedding(2626, 32)
  (merge_layer): MergeLayer(
    (fc1): Linear(in_features=64, out_features=32, bias=True)
    (fc2): Linear(in_features=32, out_features=32, bias=True)
    (act): ReLU()
  )
  (attn_model_list): ModuleList(
    (0-1): 2 x AttnModel(
      (merger): MergeLayer(
        (fc1): Linear(in_features=96, out_features=32, bias=True)
        (fc2): Linear(in_features=32, out_features=32, bias=True)
        (act): ReLU()
      )
      (multi_head_target): MultiHeadAttention(
        (w_qs): Linear(in_features=64, out_features=64, bias=False)
        (w_ks): Linear(in_features=64, out_features=64, bias=False)
        (w_vs): Linear(in_features=64, out_features=64, bias=False)
        (attention): ScaledDotProductAttention(
          (dropout): Dropout(p=0.3, inplace=False)
          (softmax): Softmax(dim=2)
        )
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fc): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (time_encoder): TimeEncode()
  (affinity_score): MergeLayer(
    (fc1): Linear(in_features=64, out_features=32, bias=True)
    (fc2): Linear(in_features=32, out_features=1, bias=True)
    (act): ReLU()
  )
)
INFO:	trainer:	Optimizer: Adam
INFO:	trainer:	Device: cuda:0
INFO:	trainer:	Number of nodes: 2625
INFO:	trainer:	Number of edges: 100000
INFO:	callbacks:	Early stopping monitor: max_round=3, higher_better=True, tolerance=0.001
INFO:	main:	Commencing training for 3 epochs
INFO:	trainer:	Epoch 1:	Train Loss: 45.89394065515319	Train Acc: 0.6822695926309049	Train AP: 0.7011620745698056	Train F1: 0.7236339854795621	Train AUC: 0.7429393896445946
INFO:	trainer:	Epoch 2:	Train Loss: 36.5012532988591	Train Acc: 0.6858252056548939	Train AP: 0.739746584745467	Train F1: 0.668549941696285	Train AUC: 0.7661129698379732
