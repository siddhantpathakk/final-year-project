{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/FYP/siddhant005/.conda/envs/retagnn_pyg/bin/python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla V100-PCIE-32GB (UUID: GPU-73e475a7-966f-91ae-6652-4163028a8284)\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for user 850...\n",
      "User id (real) : 850 mapped to 853\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/FYP/siddhant005/fyp/src/inference.py\", line 172, in <module>\n",
      "    print(inference.run(user_id))\n",
      "  File \"/home/FYP/siddhant005/fyp/src/inference.py\", line 159, in run\n",
      "    return eval_user(self.model, src, dst, ts, \n",
      "  File \"/home/FYP/siddhant005/fyp/src/inference.py\", line 77, in eval_user\n",
      "    pred_scores = tgrec(test_src_l, test_items, test_ts, args.n_degree)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/TGSRec.py\", line 87, in forward\n",
      "    src_embed = self.tem_conv(src_idx_l, cut_time_l, self.num_layers, num_neighbors)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/TGSRec.py\", line 175, in tem_conv\n",
      "    src_ngh_node_conv_feat = self.tem_conv(src_ngh_node_batch_flat, src_ngh_t_batch_flat,num_neighbors=num_neighbors,\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/TGSRec.py\", line 192, in tem_conv\n",
      "    local, weight = attn_m(src_node_conv_feat, src_node_t_embed, # query (user, time embed)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/attention.py\", line 87, in forward\n",
      "    k, _ = self.self_attn_model(seq, seq_t, mask)        \n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/attention.py\", line 135, in forward\n",
      "    output = self.ffn(output, seq)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/layers.py\", line 43, in forward\n",
      "    x = self.fc2(self.act(self.fc1(x)))\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 101, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/functional.py\", line 1471, in relu\n",
      "    result = torch.relu(input)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.55 GiB. GPU 0 has a total capacty of 31.74 GiB of which 5.94 GiB is free. Including non-PyTorch memory, this process has 25.80 GiB memory in use. Of the allocated memory 22.47 GiB is allocated by PyTorch, and 2.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python /home/FYP/siddhant005/fyp/src/inference.py -d ml-100k --pretrain '/home/FYP/siddhant005/fyp/log/saved_models/ml-100k/190_checkpoint.128_30_200_2_0.3_disentangle_2_30_32_32_0.001.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retagnn_pyg",
   "language": "python",
   "name": "retagnn_pyg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
