running train.py with arguments: Namespace(L=11, H=3, epoch_num=30, topk=20, batch_size=256, learning_rate=0.001, l2=0.001, neg_samples=3, sets_of_neg_samples=50, dim=30, conv_layer_num=2, adj_dropout=0, num_bases=2)
[info] device: cpu 
====================================================================================================
[status] preparing data DONE
[info] node_num: 2010 
[info] relation_num: 6 
[info] user_num: 563 
[info] train_num: 3941 
[info] test_num: 563 
[info] train_set: (3941, 14) 
[info] test_set: (563, 11) 
[info] uid_list_: 563 
[info] u2v: 563 
[info] u2vc: 563 
[info] v2u: 1442 
[info] v2vc: 1442 
====================================================================================================
[status] COMMENCING training
0
0-0
Epoch 1 - loss=76.1206
0-1
Epoch 1 - loss=77.7865
0-2
Epoch 1 - loss=74.2138
0-3
Epoch 1 - loss=70.8874
0-4
Epoch 1 - loss=68.0159
0-5
Epoch 1 - loss=65.0343
0-6
Epoch 1 - loss=61.8809
0-7
Epoch 1 - loss=58.3150
0-8
Epoch 1 - loss=55.6533
0-9
Epoch 1 - loss=52.6664
0-10
Epoch 1 - loss=51.8722
0-11
Epoch 1 - loss=49.8494
0-12
Epoch 1 - loss=46.5125
0-13
Epoch 1 - loss=45.4715
0-14
Epoch 1 - loss=44.9768
0-15
Epoch 1 - loss=28.1697
precision :  [0.09413854351687409, 0.09094138543516912, 0.08727057430432238, 0.08072824156305501]
recall :  [0.023534635879218523, 0.04547069271758456, 0.0654529307282417, 0.08072824156305501]
MAP :  [0.052184724689165185, 0.0363162902816544, 0.028703024822030153, 0.023648511149246647]
ndcg :  [0.09857516431065373, 0.09498008034952513, 0.09165398719814748, 0.08652261827804332]
1
1-0
Epoch 2 - loss=36.8869
1-1
Epoch 2 - loss=33.9997
1-2
Epoch 2 - loss=35.0696
1-3
Epoch 2 - loss=31.8005
1-4
Epoch 2 - loss=32.8090
1-5
Epoch 2 - loss=33.3478
1-6
Epoch 2 - loss=31.9969
1-7
Epoch 2 - loss=30.0480
1-8
Epoch 2 - loss=30.2339
1-9
Epoch 2 - loss=29.9649
1-10
Epoch 2 - loss=30.1551
1-11
Epoch 2 - loss=32.7390
1-12
Epoch 2 - loss=28.6900
1-13
Epoch 2 - loss=28.1347
1-14
Epoch 2 - loss=28.8436
1-15
Epoch 2 - loss=16.7110
precision :  [0.07637655417406752, 0.07850799289520458, 0.08288928359976346, 0.07984014209591479]
recall :  [0.01909413854351688, 0.03925399644760229, 0.06216696269982257, 0.07984014209591479]
MAP :  [0.0474185908821788, 0.03175202289323071, 0.025850374544868326, 0.02174482309139016]
ndcg :  [0.08667673941202104, 0.08449262198857305, 0.08590945454246228, 0.08336620087731626]
2
2-0
Epoch 3 - loss=27.8822
2-1
Epoch 3 - loss=25.6662
2-2
Epoch 3 - loss=22.9623
2-3
Epoch 3 - loss=21.5745
2-4
Epoch 3 - loss=24.7113
2-5
Epoch 3 - loss=27.8064
2-6
Epoch 3 - loss=25.1631
2-7
Epoch 3 - loss=24.9906
2-8
Epoch 3 - loss=22.6505
2-9
Epoch 3 - loss=23.0130
2-10
Epoch 3 - loss=24.1698
2-11
Epoch 3 - loss=26.3209
2-12
Epoch 3 - loss=24.1949
2-13
Epoch 3 - loss=22.4507
2-14
Epoch 3 - loss=22.9186
2-15
Epoch 3 - loss=11.7871
precision :  [0.10905861456483155, 0.09094138543516915, 0.08786264061574926, 0.08436944937833041]
recall :  [0.02726465364120789, 0.045470692717584575, 0.06589698046181186, 0.08436944937833041]
MAP :  [0.05820011841326228, 0.03748681947616228, 0.02958623114928621, 0.024804335801681125]
ndcg :  [0.11140804050022178, 0.0982368440380945, 0.09449817149621015, 0.09099668019539514]
3
3-0
Epoch 4 - loss=23.3096
3-1
Epoch 4 - loss=21.5481
3-2
Epoch 4 - loss=21.0072
3-3
Epoch 4 - loss=20.1321
3-4
Epoch 4 - loss=21.6770
3-5
Epoch 4 - loss=20.5726
3-6
Epoch 4 - loss=21.3496
3-7
Epoch 4 - loss=21.2066
3-8
Epoch 4 - loss=19.8379
3-9
Epoch 4 - loss=21.3672
3-10
Epoch 4 - loss=19.6720
3-11
Epoch 4 - loss=22.1606
3-12
Epoch 4 - loss=20.4553
3-13
Epoch 4 - loss=20.0443
3-14
Epoch 4 - loss=21.0474
3-15
Epoch 4 - loss=10.1837
precision :  [0.08952042628774437, 0.09147424511545336, 0.08703374777975169, 0.08303730017761982]
recall :  [0.022380106571936093, 0.04573712255772668, 0.06527531083481358, 0.08303730017761982]
MAP :  [0.04940793368857312, 0.03474266260678339, 0.02748738039146565, 0.023045558126951204]
ndcg :  [0.09453235281415341, 0.09444200046478249, 0.09074337419344382, 0.08740161080596578]
4
4-0
Epoch 5 - loss=22.7120
4-1
Epoch 5 - loss=19.5219
4-2
Epoch 5 - loss=21.4016
4-3
Epoch 5 - loss=19.5077
4-4
Epoch 5 - loss=19.3608
4-5
Epoch 5 - loss=19.6025
4-6
Epoch 5 - loss=20.0748
4-7
Epoch 5 - loss=18.8809
4-8
Epoch 5 - loss=19.2793
4-9
Epoch 5 - loss=20.1806
4-10
Epoch 5 - loss=19.6861
4-11
Epoch 5 - loss=21.0901
4-12
Epoch 5 - loss=19.7140
4-13
Epoch 5 - loss=19.5368
4-14
Epoch 5 - loss=20.7784
4-15
Epoch 5 - loss=9.5252
precision :  [0.0930728241563057, 0.08721136767317975, 0.08608644168146865, 0.08392539964476012]
recall :  [0.023268206039076426, 0.04360568383658987, 0.06456483126110137, 0.08392539964476012]
MAP :  [0.05104203670811131, 0.033953029405960136, 0.02720061597503871, 0.023233088760762133]
ndcg :  [0.09914094806743332, 0.09234405630716339, 0.09042654726874819, 0.08827131414743314]
5
5-0
Epoch 6 - loss=21.9384
5-1
Epoch 6 - loss=21.0295
5-2
Epoch 6 - loss=20.8007
5-3
Epoch 6 - loss=18.5282
5-4
Epoch 6 - loss=19.5918
5-5
Epoch 6 - loss=20.5915
5-6
Epoch 6 - loss=19.3659
5-7
Epoch 6 - loss=18.3511
5-8
Epoch 6 - loss=19.4896
5-9
Epoch 6 - loss=20.5718
5-10
Epoch 6 - loss=18.9887
5-11
Epoch 6 - loss=20.8282
5-12
Epoch 6 - loss=19.4671
5-13
Epoch 6 - loss=19.5988
5-14
Epoch 6 - loss=19.8235
5-15
Epoch 6 - loss=8.8120
precision :  [0.09342806394316187, 0.08348134991119041, 0.08691533451746626, 0.07948490230905861]
recall :  [0.02335701598579047, 0.041740674955595206, 0.06518650088809956, 0.07948490230905861]
MAP :  [0.04536412078152754, 0.03078780061462122, 0.025658675578746626, 0.021325212947376118]
ndcg :  [0.09105256368020984, 0.0852976440540639, 0.08717786441864998, 0.08225335729693618]
6
6-0
Epoch 7 - loss=23.0130
6-1
Epoch 7 - loss=20.2901
6-2
Epoch 7 - loss=17.7529
6-3
Epoch 7 - loss=17.4606
6-4
Epoch 7 - loss=19.2974
6-5
Epoch 7 - loss=21.0507
6-6
Epoch 7 - loss=19.7289
6-7
Epoch 7 - loss=18.7431
6-8
Epoch 7 - loss=20.0517
6-9
Epoch 7 - loss=18.3856
6-10
Epoch 7 - loss=18.6743
6-11
Epoch 7 - loss=20.6410
6-12
Epoch 7 - loss=18.6618
6-13
Epoch 7 - loss=20.0154
6-14
Epoch 7 - loss=20.2365
6-15
Epoch 7 - loss=8.3977
precision :  [0.09591474245115468, 0.09289520426287792, 0.08975725281231528, 0.08614564831261101]
recall :  [0.02397868561278867, 0.04644760213143896, 0.06731793960923635, 0.08614564831261101]
MAP :  [0.046033155713439904, 0.033173475429248075, 0.026832204700765982, 0.022953028718729243]
ndcg :  [0.09169221867727054, 0.09109044056304813, 0.08947653685360692, 0.08716066291180373]
7
7-0
Epoch 8 - loss=20.0312
7-1
Epoch 8 - loss=18.0270
7-2
Epoch 8 - loss=18.5499
7-3
Epoch 8 - loss=16.3765
7-4
Epoch 8 - loss=18.3232
7-5
Epoch 8 - loss=19.4942
7-6
Epoch 8 - loss=20.3171
7-7
Epoch 8 - loss=18.5835
7-8
Epoch 8 - loss=17.6787
7-9
Epoch 8 - loss=18.2173
7-10
Epoch 8 - loss=16.9151
7-11
Epoch 8 - loss=18.7787
7-12
Epoch 8 - loss=18.8286
7-13
Epoch 8 - loss=18.3088
7-14
Epoch 8 - loss=19.4005
7-15
Epoch 8 - loss=7.8182
precision :  [0.10515097690941413, 0.09271758436944977, 0.08963883955002991, 0.0831261101243339]
recall :  [0.026287744227353534, 0.046358792184724884, 0.0672291296625223, 0.0831261101243339]
MAP :  [0.053824748371817645, 0.036027939891172575, 0.02887492679677404, 0.02383004805311568]
ndcg :  [0.1042956393453321, 0.0959071353307448, 0.09318500190319391, 0.08823771035926412]
8
8-0
Epoch 9 - loss=19.3217
8-1
Epoch 9 - loss=18.0439
8-2
Epoch 9 - loss=18.0159
8-3
Epoch 9 - loss=16.6425
8-4
Epoch 9 - loss=17.2468
8-5
Epoch 9 - loss=20.5019
8-6
Epoch 9 - loss=19.5811
8-7
Epoch 9 - loss=17.0240
8-8
Epoch 9 - loss=16.7985
8-9
Epoch 9 - loss=17.6603
8-10
Epoch 9 - loss=17.1610
8-11
Epoch 9 - loss=18.8894
8-12
Epoch 9 - loss=18.3209
8-13
Epoch 9 - loss=17.5037
8-14
Epoch 9 - loss=18.5602
8-15
Epoch 9 - loss=7.8842
precision :  [0.09698046181172314, 0.09698046181172336, 0.09070455891059832, 0.08792184724689157]
recall :  [0.024245115452930784, 0.04849023090586168, 0.06802841918294861, 0.08792184724689157]
MAP :  [0.047134399052693905, 0.03405924892159351, 0.027136016736371976, 0.023270623750458668]
ndcg :  [0.09260753419866263, 0.09405040628787377, 0.09037573989148505, 0.08858564726773094]
9
9-0
Epoch 10 - loss=19.9246
9-1
Epoch 10 - loss=18.8953
9-2
Epoch 10 - loss=18.4776
9-3
Epoch 10 - loss=16.8138
9-4
Epoch 10 - loss=16.7683
9-5
Epoch 10 - loss=19.2551
9-6
Epoch 10 - loss=19.2918
9-7
Epoch 10 - loss=17.7138
9-8
Epoch 10 - loss=17.2266
9-9
Epoch 10 - loss=17.4799
9-10
Epoch 10 - loss=18.4332
9-11
Epoch 10 - loss=19.5970
9-12
Epoch 10 - loss=17.2250
9-13
Epoch 10 - loss=16.6052
9-14
Epoch 10 - loss=17.1424
9-15
Epoch 10 - loss=7.5184
precision :  [0.09591474245115475, 0.09147424511545342, 0.08656009473061016, 0.08259325044404967]
recall :  [0.023978685612788687, 0.04573712255772671, 0.0649200710479575, 0.08259325044404967]
MAP :  [0.0506275902901125, 0.03515421917730976, 0.027984213010855994, 0.02354270249231522]
ndcg :  [0.09732409217342623, 0.09372620153236012, 0.09001167971413992, 0.08676150528644165]
10
10-0
Epoch 11 - loss=19.3193
10-1
Epoch 11 - loss=17.5337
10-2
Epoch 11 - loss=16.8844
10-3
Epoch 11 - loss=16.6920
10-4
Epoch 11 - loss=18.0962
10-5
Epoch 11 - loss=17.5499
10-6
Epoch 11 - loss=16.6788
10-7
Epoch 11 - loss=18.5521
10-8
Epoch 11 - loss=16.6508
10-9
Epoch 11 - loss=18.6348
10-10
Epoch 11 - loss=17.0874
10-11
Epoch 11 - loss=17.7714
10-12
Epoch 11 - loss=16.8877
10-13
Epoch 11 - loss=16.8878
10-14
Epoch 11 - loss=17.8924
10-15
Epoch 11 - loss=6.6923
precision :  [0.10550621669627024, 0.0902309058614569, 0.08312611012433417, 0.08197158081705141]
recall :  [0.02637655417406756, 0.04511545293072845, 0.06234458259325061, 0.08197158081705141]
MAP :  [0.053925399644760216, 0.035155910795342415, 0.0271178620734571, 0.023158704658702595]
ndcg :  [0.1048096059499309, 0.09438809920907308, 0.08854052205828085, 0.0868536473219571]
11
11-0
Epoch 12 - loss=18.3592
11-1
Epoch 12 - loss=16.3603
11-2
Epoch 12 - loss=16.5627
11-3
Epoch 12 - loss=15.8594
11-4
Epoch 12 - loss=16.3204
11-5
Epoch 12 - loss=17.2821
11-6
Epoch 12 - loss=16.0319
11-7
Epoch 12 - loss=16.5206
11-8
Epoch 12 - loss=16.0847
11-9
Epoch 12 - loss=17.0291
11-10
Epoch 12 - loss=16.6474
11-11
Epoch 12 - loss=16.8289
11-12
Epoch 12 - loss=16.1087
11-13
Epoch 12 - loss=16.1879
11-14
Epoch 12 - loss=16.0902
11-15
Epoch 12 - loss=6.5053
precision :  [0.09840142095914764, 0.08632326820603947, 0.07838957963291918, 0.07690941385435156]
recall :  [0.02460035523978691, 0.043161634103019736, 0.05879218472468937, 0.07690941385435156]
MAP :  [0.055340438129070454, 0.03525515238659111, 0.026808379437153855, 0.022461225276528083]
ndcg :  [0.10405850813573544, 0.09365229584063238, 0.08664556310377931, 0.08424505862832296]
12
12-0
Epoch 13 - loss=16.0904
12-1
Epoch 13 - loss=16.3744
12-2
Epoch 13 - loss=15.4453
12-3
Epoch 13 - loss=15.6780
12-4
Epoch 13 - loss=15.8492
12-5
Epoch 13 - loss=14.6310
12-6
Epoch 13 - loss=17.6195
12-7
Epoch 13 - loss=16.1458
12-8
Epoch 13 - loss=15.7853
12-9
Epoch 13 - loss=16.2084
12-10
Epoch 13 - loss=15.8619
12-11
Epoch 13 - loss=15.4733
12-12
Epoch 13 - loss=14.6258
12-13
Epoch 13 - loss=16.5279
12-14
Epoch 13 - loss=16.8078
12-15
Epoch 13 - loss=7.4909
precision :  [0.0909413854351689, 0.08596802841918336, 0.07957371225577292, 0.07575488454706923]
recall :  [0.022735346358792225, 0.04298401420959168, 0.05968028419182968, 0.07575488454706923]
MAP :  [0.05033747779751332, 0.0331798894809552, 0.025664071143644853, 0.021415466675620706]
ndcg :  [0.09625349992044843, 0.09081926492901009, 0.08543203535838365, 0.08185964174025277]
13
13-0
Epoch 14 - loss=17.5108
13-1
Epoch 14 - loss=15.3630
13-2
Epoch 14 - loss=13.9313
13-3
Epoch 14 - loss=15.3746
13-4
Epoch 14 - loss=13.9669
13-5
Epoch 14 - loss=15.3604
13-6
Epoch 14 - loss=14.3111
13-7
Epoch 14 - loss=14.9855
13-8
Epoch 14 - loss=14.5398
13-9
Epoch 14 - loss=14.6521
13-10
Epoch 14 - loss=15.3522
13-11
Epoch 14 - loss=15.2256
13-12
Epoch 14 - loss=15.6131
13-13
Epoch 14 - loss=16.0430
13-14
Epoch 14 - loss=14.9099
13-15
Epoch 14 - loss=5.4805
precision :  [0.09769094138543537, 0.09271758436944981, 0.08786264061574935, 0.08312611012433395]
recall :  [0.024422735346358842, 0.046358792184724905, 0.06589698046181183, 0.08312611012433395]
MAP :  [0.05228537596210776, 0.036025684400462374, 0.02824745940198871, 0.023670875379724482]
ndcg :  [0.1012658373670268, 0.09681330633348909, 0.09269401354842013, 0.08873718280287243]
14
14-0
Epoch 15 - loss=14.4484
14-1
Epoch 15 - loss=15.0868
14-2
Epoch 15 - loss=14.4467
14-3
Epoch 15 - loss=13.4894
14-4
Epoch 15 - loss=14.2598
14-5
Epoch 15 - loss=15.9048
14-6
Epoch 15 - loss=13.3390
14-7
Epoch 15 - loss=12.2314
14-8
Epoch 15 - loss=13.8914
14-9
Epoch 15 - loss=15.2405
14-10
Epoch 15 - loss=14.7471
14-11
Epoch 15 - loss=14.9958
14-12
Epoch 15 - loss=13.3161
14-13
Epoch 15 - loss=12.4180
14-14
Epoch 15 - loss=14.6457
14-15
Epoch 15 - loss=5.7255
precision :  [0.09946714031971605, 0.09396092362344628, 0.08809946714032009, 0.08357015985790404]
recall :  [0.024866785079929014, 0.04698046181172314, 0.06607460035523986, 0.08357015985790404]
MAP :  [0.05512729425695678, 0.037264019284445574, 0.029073368904630005, 0.024175331925622]
ndcg :  [0.1033935733385451, 0.09812840518491757, 0.09326691095951056, 0.08935524344608602]
15
15-0
Epoch 16 - loss=12.9932
15-1
Epoch 16 - loss=13.4641
15-2
Epoch 16 - loss=12.5574
15-3
Epoch 16 - loss=10.7827
15-4
Epoch 16 - loss=13.0900
15-5
Epoch 16 - loss=14.6599
15-6
Epoch 16 - loss=14.1129
15-7
Epoch 16 - loss=14.9232
15-8
Epoch 16 - loss=14.2097
15-9
Epoch 16 - loss=13.3095
15-10
Epoch 16 - loss=13.6243
15-11
Epoch 16 - loss=14.7879
15-12
Epoch 16 - loss=13.2686
15-13
Epoch 16 - loss=13.1298
15-14
Epoch 16 - loss=11.3643
15-15
Epoch 16 - loss=4.7306
precision :  [0.09875666074600374, 0.08898756660746038, 0.08229721728833661, 0.07904085257548836]
recall :  [0.024689165186500935, 0.04449378330373019, 0.061722912966252395, 0.07904085257548836]
MAP :  [0.05291888691533451, 0.0356554315035665, 0.027383928813768953, 0.023051100075258853]
ndcg :  [0.10049612690400181, 0.09318842141751733, 0.08770754196117372, 0.08466189508565064]
16
16-0
Epoch 17 - loss=13.5187
16-1
Epoch 17 - loss=13.8702
16-2
Epoch 17 - loss=12.1244
16-3
Epoch 17 - loss=11.8618
16-4
Epoch 17 - loss=11.8664
16-5
Epoch 17 - loss=13.2199
16-6
Epoch 17 - loss=11.3779
16-7
Epoch 17 - loss=13.9326
16-8
Epoch 17 - loss=13.9129
16-9
Epoch 17 - loss=10.3888
16-10
Epoch 17 - loss=10.8783
16-11
Epoch 17 - loss=14.3038
16-12
Epoch 17 - loss=11.0408
16-13
Epoch 17 - loss=12.7076
16-14
Epoch 17 - loss=13.3909
16-15
Epoch 17 - loss=5.2469
precision :  [0.09662522202486698, 0.08703374777975173, 0.08277087033747813, 0.07921847246891649]
recall :  [0.024156305506216745, 0.043516873889875865, 0.06207815275310848, 0.07921847246891649]
MAP :  [0.05268206039076376, 0.035068510530322256, 0.027307383754985887, 0.02289371478968686]
ndcg :  [0.09966730304752439, 0.09184189194660539, 0.08792682170150763, 0.08470475676812331]
17
17-0
Epoch 18 - loss=13.8501
17-1
Epoch 18 - loss=12.2191
17-2
Epoch 18 - loss=12.5334
17-3
Epoch 18 - loss=11.7810
17-4
Epoch 18 - loss=12.4427
17-5
Epoch 18 - loss=12.4169
17-6
Epoch 18 - loss=12.5542
17-7
Epoch 18 - loss=12.4237
17-8
Epoch 18 - loss=14.2676
17-9
Epoch 18 - loss=12.3385
17-10
Epoch 18 - loss=12.1678
17-11
Epoch 18 - loss=11.5846
17-12
Epoch 18 - loss=12.0215
17-13
Epoch 18 - loss=12.4078
17-14
Epoch 18 - loss=11.7014
17-15
Epoch 18 - loss=5.4334
precision :  [0.0891651865008883, 0.08348134991119043, 0.08040260509177058, 0.07921847246891645]
recall :  [0.022291296625222074, 0.04174067495559521, 0.06030195381882789, 0.07921847246891645]
MAP :  [0.04745411486086442, 0.03251910118695198, 0.025653599081663023, 0.0219303872480031]
ndcg :  [0.09111898531111336, 0.08671954831821091, 0.0839313097907561, 0.08254593324798133]
18
18-0
Epoch 19 - loss=12.0331
18-1
Epoch 19 - loss=11.9556
18-2
Epoch 19 - loss=11.6299
18-3
Epoch 19 - loss=11.1862
18-4
Epoch 19 - loss=13.2235
18-5
Epoch 19 - loss=12.1298
18-6
Epoch 19 - loss=10.9397
18-7
Epoch 19 - loss=10.8122
18-8
Epoch 19 - loss=11.6034
18-9
Epoch 19 - loss=12.0295
18-10
Epoch 19 - loss=12.3924
18-11
Epoch 19 - loss=12.6497
18-12
Epoch 19 - loss=11.5309
18-13
Epoch 19 - loss=12.0839
18-14
Epoch 19 - loss=10.8234
18-15
Epoch 19 - loss=4.7414
precision :  [0.09342806394316183, 0.08898756660746053, 0.08478389579632949, 0.08108348134991118]
recall :  [0.023357015985790458, 0.044493783303730265, 0.06358792184724704, 0.08108348134991118]
MAP :  [0.048247483718176436, 0.03325798584679579, 0.02627848600317517, 0.0223124741974825]
ndcg :  [0.09393794475831538, 0.09053018919797708, 0.08735389251955347, 0.08443062171294835]
19
19-0
Epoch 20 - loss=13.2677
19-1
Epoch 20 - loss=11.9041
19-2
Epoch 20 - loss=10.9322
19-3
Epoch 20 - loss=10.6008
19-4
Epoch 20 - loss=10.5184
19-5
Epoch 20 - loss=9.6219
19-6
Epoch 20 - loss=10.1325
19-7
Epoch 20 - loss=10.5335
19-8
Epoch 20 - loss=11.1681
19-9
Epoch 20 - loss=10.8782
19-10
Epoch 20 - loss=10.5417
19-11
Epoch 20 - loss=11.3330
19-12
Epoch 20 - loss=11.0452
19-13
Epoch 20 - loss=11.0493
19-14
Epoch 20 - loss=11.8377
19-15
Epoch 20 - loss=5.2384
precision :  [0.09165186500888117, 0.08667850799289556, 0.07921847246891683, 0.07673179396092356]
recall :  [0.022912966252220293, 0.04333925399644778, 0.059413854351687556, 0.07673179396092356]
MAP :  [0.051450562462995855, 0.034690292931855986, 0.026596490806082278, 0.022243485961196123]
ndcg :  [0.09715202281518835, 0.09170539045415199, 0.0856160741194972, 0.08289619660557204]
20
20-0
Epoch 21 - loss=11.6145
20-1
Epoch 21 - loss=11.6651
20-2
Epoch 21 - loss=10.8159
20-3
Epoch 21 - loss=11.0568
20-4
Epoch 21 - loss=10.5127
20-5
Epoch 21 - loss=11.4989
20-6
Epoch 21 - loss=11.3605
20-7
Epoch 21 - loss=11.4404
20-8
Epoch 21 - loss=10.2097
20-9
Epoch 21 - loss=9.9595
20-10
Epoch 21 - loss=10.9391
20-11
Epoch 21 - loss=11.7265
20-12
Epoch 21 - loss=9.9381
20-13
Epoch 21 - loss=10.5141
20-14
Epoch 21 - loss=10.8145
20-15
Epoch 21 - loss=4.9627
precision :  [0.09520426287744249, 0.07850799289520459, 0.07353463587921863, 0.07477797513321484]
recall :  [0.023801065719360623, 0.039253996447602295, 0.05515097690941412, 0.07477797513321484]
MAP :  [0.05156305506216696, 0.032456934224252165, 0.024893473081750165, 0.021415756957995986]
ndcg :  [0.09846009392523228, 0.08559910988571305, 0.08067382556011765, 0.08033967057955244]
21
21-0
Epoch 22 - loss=12.8109
21-1
Epoch 22 - loss=9.9140
21-2
Epoch 22 - loss=10.3458
21-3
Epoch 22 - loss=10.9229
21-4
Epoch 22 - loss=10.7357
21-5
Epoch 22 - loss=11.2922
21-6
Epoch 22 - loss=9.3474
21-7
Epoch 22 - loss=9.5961
21-8
Epoch 22 - loss=10.5406
21-9
Epoch 22 - loss=10.0668
21-10
Epoch 22 - loss=10.8385
21-11
Epoch 22 - loss=10.7143
21-12
Epoch 22 - loss=9.5456
21-13
Epoch 22 - loss=9.0768
21-14
Epoch 22 - loss=10.8010
21-15
Epoch 22 - loss=4.2165
precision :  [0.0891651865008882, 0.07602131438721169, 0.07341622261693327, 0.07273534635879217]
recall :  [0.02229129662522205, 0.03801065719360584, 0.05506216696270008, 0.07273534635879217]
MAP :  [0.04778567199526348, 0.03073063802193465, 0.024251409402386306, 0.020552793848374936]
ndcg :  [0.09240475895481484, 0.08200806392822933, 0.07887093768551459, 0.07748436835450777]
22
22-0
Epoch 23 - loss=10.1927
22-1
Epoch 23 - loss=9.7287
22-2
Epoch 23 - loss=11.4738
22-3
Epoch 23 - loss=10.0736
22-4
Epoch 23 - loss=11.1459
22-5
Epoch 23 - loss=9.4791
22-6
Epoch 23 - loss=9.1852
22-7
Epoch 23 - loss=9.5124
22-8
Epoch 23 - loss=11.3050
22-9
Epoch 23 - loss=9.8364
22-10
Epoch 23 - loss=10.1967
22-11
Epoch 23 - loss=10.5076
22-12
Epoch 23 - loss=9.8420
22-13
Epoch 23 - loss=10.3135
22-14
Epoch 23 - loss=9.9657
22-15
Epoch 23 - loss=4.5712
precision :  [0.08454706927175852, 0.08099467140319751, 0.07886323268206055, 0.07628774422735349]
recall :  [0.02113676731793963, 0.040497335701598754, 0.05914742451154552, 0.07628774422735349]
MAP :  [0.042759029011249255, 0.029825340438129067, 0.024121020089048505, 0.020411901773003567]
ndcg :  [0.0836490642652795, 0.08157296312164274, 0.0800522623864236, 0.07811727629312898]
23
23-0
Epoch 24 - loss=9.8743
23-1
Epoch 24 - loss=11.3135
23-2
Epoch 24 - loss=10.3602
23-3
Epoch 24 - loss=9.8586
23-4
Epoch 24 - loss=9.3136
23-5
Epoch 24 - loss=10.4615
23-6
Epoch 24 - loss=8.7830
23-7
Epoch 24 - loss=10.1709
23-8
Epoch 24 - loss=9.4855
23-9
Epoch 24 - loss=8.9122
23-10
Epoch 24 - loss=10.0561
23-11
Epoch 24 - loss=11.3223
23-12
Epoch 24 - loss=9.3800
23-13
Epoch 24 - loss=8.9407
23-14
Epoch 24 - loss=8.8661
23-15
Epoch 24 - loss=3.9168
precision :  [0.08348134991119013, 0.08241563055062205, 0.08146832445233895, 0.07690941385435163]
recall :  [0.020870337477797533, 0.041207815275311026, 0.06110124333925417, 0.07690941385435163]
MAP :  [0.0426939017169923, 0.030170501000874, 0.024742322673050914, 0.020738146631703928]
ndcg :  [0.08404309320880703, 0.0833644224511339, 0.08252675274533121, 0.07932961313202175]
24
24-0
Epoch 25 - loss=10.8617
24-1
Epoch 25 - loss=9.6805
24-2
Epoch 25 - loss=9.2438
24-3
Epoch 25 - loss=9.7554
24-4
Epoch 25 - loss=9.2304
24-5
Epoch 25 - loss=9.7699
24-6
Epoch 25 - loss=9.8724
24-7
Epoch 25 - loss=9.9049
24-8
Epoch 25 - loss=9.8700
24-9
Epoch 25 - loss=8.8077
24-10
Epoch 25 - loss=9.6872
24-11
Epoch 25 - loss=9.5861
24-12
Epoch 25 - loss=8.6291
24-13
Epoch 25 - loss=10.1115
24-14
Epoch 25 - loss=9.4879
24-15
Epoch 25 - loss=3.8444
precision :  [0.08952042628774438, 0.08454706927175884, 0.08099467140319738, 0.07735346358792185]
recall :  [0.022380106571936096, 0.04227353463587942, 0.060746003552398085, 0.07735346358792185]
MAP :  [0.04441681468324452, 0.03106381629028165, 0.02475415939891961, 0.02088063548732153]
ndcg :  [0.08757946109580582, 0.08470783072122616, 0.08231731133406044, 0.0796757054795697]
25
25-0
Epoch 26 - loss=9.0944
25-1
Epoch 26 - loss=9.2949
25-2
Epoch 26 - loss=9.4495
25-3
Epoch 26 - loss=9.1351
25-4
Epoch 26 - loss=9.4631
25-5
Epoch 26 - loss=10.1473
25-6
Epoch 26 - loss=7.9945
25-7
Epoch 26 - loss=9.9105
25-8
Epoch 26 - loss=10.4622
25-9
Epoch 26 - loss=8.5545
25-10
Epoch 26 - loss=10.7996
25-11
Epoch 26 - loss=9.2346
25-12
Epoch 26 - loss=7.4362
25-13
Epoch 26 - loss=9.4720
25-14
Epoch 26 - loss=9.6361
25-15
Epoch 26 - loss=4.2844
precision :  [0.08703374777975147, 0.0843694493783308, 0.07767910005920686, 0.07602131438721133]
recall :  [0.021758436944937867, 0.0421847246891654, 0.05825932504440523, 0.07602131438721133]
MAP :  [0.04631734754292481, 0.0320017480053004, 0.02463878664589144, 0.020857992871490334]
ndcg :  [0.08787527407681821, 0.08563013726865132, 0.08081989246614653, 0.0791778608512935]
26
26-0
Epoch 27 - loss=10.6309
26-1
Epoch 27 - loss=11.0011
26-2
Epoch 27 - loss=8.6218
26-3
Epoch 27 - loss=10.1723
26-4
Epoch 27 - loss=9.2019
26-5
Epoch 27 - loss=8.6611
26-6
Epoch 27 - loss=7.5070
26-7
Epoch 27 - loss=8.1751
26-8
Epoch 27 - loss=10.6167
26-9
Epoch 27 - loss=9.7689
26-10
Epoch 27 - loss=8.5838
26-11
Epoch 27 - loss=9.8183
26-12
Epoch 27 - loss=8.9078
26-13
Epoch 27 - loss=8.5186
26-14
Epoch 27 - loss=7.8161
26-15
Epoch 27 - loss=3.7482
precision :  [0.08312611012433403, 0.07815275310834853, 0.07554766133806999, 0.07317939609236238]
recall :  [0.020781527531083508, 0.039076376554174265, 0.05666074600355268, 0.07317939609236238]
MAP :  [0.0456542332741267, 0.03010769968141194, 0.023843731428100874, 0.020029727479125743]
ndcg :  [0.08646561551159031, 0.08161345018164018, 0.079105039933344, 0.07695420907754248]
27
27-0
Epoch 28 - loss=8.0392
27-1
Epoch 28 - loss=9.0305
27-2
Epoch 28 - loss=8.8373
27-3
Epoch 28 - loss=8.1205
27-4
Epoch 28 - loss=7.8579
27-5
Epoch 28 - loss=8.9668
27-6
Epoch 28 - loss=8.6007
27-7
Epoch 28 - loss=9.0178
27-8
Epoch 28 - loss=8.8431
27-9
Epoch 28 - loss=8.5797
27-10
Epoch 28 - loss=8.8674
27-11
Epoch 28 - loss=8.8114
27-12
Epoch 28 - loss=7.3838
27-13
Epoch 28 - loss=8.6205
27-14
Epoch 28 - loss=9.0559
27-15
Epoch 28 - loss=4.2524
precision :  [0.08312611012433407, 0.0776198934280643, 0.07448194197750167, 0.07220248667850807]
recall :  [0.02078152753108352, 0.03880994671403215, 0.055861456483126404, 0.07220248667850807]
MAP :  [0.044754292480757844, 0.02969494488144577, 0.023219230608218174, 0.019469137459833037]
ndcg :  [0.08640633097864826, 0.08129788163605232, 0.07830723414991829, 0.07611769268686858]
28
28-0
Epoch 29 - loss=9.5127
28-1
Epoch 29 - loss=9.7529
28-2
Epoch 29 - loss=8.8719
28-3
Epoch 29 - loss=8.3236
28-4
Epoch 29 - loss=7.9227
28-5
Epoch 29 - loss=7.7448
28-6
Epoch 29 - loss=7.6558
28-7
Epoch 29 - loss=9.7861
28-8
Epoch 29 - loss=10.1301
28-9
Epoch 29 - loss=8.1095
28-10
Epoch 29 - loss=8.8814
28-11
Epoch 29 - loss=8.3585
28-12
Epoch 29 - loss=7.8516
28-13
Epoch 29 - loss=7.9004
28-14
Epoch 29 - loss=8.3705
28-15
Epoch 29 - loss=3.4906
precision :  [0.08880994671403218, 0.07761989342806426, 0.07483718176435787, 0.07113676731793966]
recall :  [0.022202486678508045, 0.03880994671403213, 0.05612788632326848, 0.07113676731793966]
MAP :  [0.047152161042036705, 0.030704770362852067, 0.023758131546763872, 0.019782759554245785]
ndcg :  [0.09187048849385865, 0.08296162910217589, 0.07997134477085979, 0.0766580585788385]
29
29-0
Epoch 30 - loss=7.0650
29-1
Epoch 30 - loss=8.0183
29-2
Epoch 30 - loss=10.1044
29-3
Epoch 30 - loss=8.6990
29-4
Epoch 30 - loss=7.9905
29-5
Epoch 30 - loss=9.7903
29-6
Epoch 30 - loss=7.5987
29-7
Epoch 30 - loss=9.4112
29-8
Epoch 30 - loss=10.5200
29-9
Epoch 30 - loss=8.5065
29-10
Epoch 30 - loss=9.6757
29-11
Epoch 30 - loss=8.8711
29-12
Epoch 30 - loss=8.6140
29-13
Epoch 30 - loss=10.2105
29-14
Epoch 30 - loss=7.9203
29-15
Epoch 30 - loss=4.0764
precision :  [0.08880994671403215, 0.08259325044405011, 0.07838957963291913, 0.07504440497335699]
recall :  [0.02220248667850804, 0.041296625222025055, 0.058792184724689354, 0.07504440497335699]
MAP :  [0.048413262285375964, 0.03224350841579972, 0.0251492005133213, 0.021146158585170483]
ndcg :  [0.09280527136091024, 0.08714250893101554, 0.08326358790092679, 0.08020458456916395]
[status] train DONE
====================================================================================================
