{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla V100-PCIE-32GB (UUID: GPU-6836cac4-6472-db93-c539-eaa93a70b15b)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/FYP/siddhant005/.conda/envs/retagnn_pyg/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:\tmain:\tNamespace(n_degree=20, n_head=2, n_layer=2, drop_out=0.1, reg=0.1, node_dim=32, time_dim=32, agg_method='attn', attn_mode='map', uniform=True, new_node=False, time='disentangle', disencomponents=10, data='ml-100k', samplerate=1.0, popnegsample=False, timepopnegsample=False, negsampleeval=-1, bs=256, n_epoch=200, lr=0.001, prefix='ml100k', gpu=0, seed=42, l2=0.0001)\n",
      "INFO:\tattention_model:\tUsing scaled prod attention\n",
      "INFO:\tattention_model:\tUsing scaled prod attention\n",
      "INFO:\tTGSRec:\tAggregation uses attention model\n",
      "INFO:\tattention_model:\tUsing map based attention\n",
      "INFO:\tattention_model:\tUsing map based attention\n",
      "INFO:\tTGSRec:\tUsing disentangle time encoding\n",
      "INFO:\ttrainer:\tModel built successfully\n",
      "INFO:\ttrainer:\tTGRec(\n",
      "  (node_hist_embed): Embedding(2626, 32)\n",
      "  (merge_layer): MergeLayer(\n",
      "    (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (self_attn_model_list): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionModel(\n",
      "      (ffn): MergeLayer(\n",
      "        (fc1): Linear(in_features=96, out_features=32, bias=True)\n",
      "        (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (multi_head_target): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (w_ks): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (w_vs): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (softmax): Softmax(dim=2)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attn_model_list): ModuleList(\n",
      "    (0-1): 2 x CrossAttentionModel(\n",
      "      (ffn): MergeLayer(\n",
      "        (fc1): Linear(in_features=96, out_features=32, bias=True)\n",
      "        (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (multi_head_target): MapBasedMultiHeadAttention(\n",
      "        (wq_node_transform): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (wk_node_transform): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (wv_node_transform): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (act): LeakyReLU(negative_slope=0.2)\n",
      "        (weight_map): Linear(in_features=64, out_features=1, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (softmax): Softmax(dim=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (time_encoder): DisentangleTimeEncode()\n",
      "  (affinity_score): MergeLayer(\n",
      "    (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      ")\n",
      "INFO:\ttrainer:\tOptimizer: Adam with lr: 0.001 and l2: 0.0001\n",
      "INFO:\ttrainer:\tLearning rate scheduler: LinearLR\n",
      "INFO:\ttrainer:\tWarmup scheduler: LinearWarmup\n",
      "INFO:\ttrainer:\tDevice: cuda:0\n",
      "INFO:\ttrainer:\tNumber of nodes: 2625\n",
      "INFO:\ttrainer:\tNumber of edges: 100000\n",
      "INFO:\tcallbacks:\tEarly stopping monitor: max_round=7, higher_better=True, tolerance=0.001\n",
      "INFO:\tmain:\tCommencing training for 200 epochs\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/FYP/siddhant005/fyp/src/main.py\", line 26, in <module>\n",
      "    trainer.train()\n",
      "  File \"/home/FYP/siddhant005/fyp/src/trainer.py\", line 172, in train\n",
      "    m_loss, acc, ap, f1, auc = self.train_for_one_epoch()\n",
      "  File \"/home/FYP/siddhant005/fyp/src/trainer.py\", line 118, in train_for_one_epoch\n",
      "    pos_score, neg_score = self.model.contrast_nosigmoid(src_l_cut, dst_l_cut, dst_l_fake, ts_l_cut, self.args.n_degree)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/TGSRec.py\", line 106, in contrast_nosigmoid\n",
      "    src_embed = self.tem_conv(src_idx_l, cut_time_l, self.num_layers, num_neighbors)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/TGSRec.py\", line 156, in tem_conv\n",
      "    src_node_conv_feat = self.tem_conv(src_idx_l, \n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/TGSRec.py\", line 196, in tem_conv\n",
      "    src_node_t_embed, _ = self_attn_m(src_ngh_feat, \n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/attention_model.py\", line 112, in forward\n",
      "    output = self.ffn(output, src)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/.conda/envs/retagnn_pyg/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/FYP/siddhant005/fyp/src/model/components/ffn.py\", line 21, in forward\n",
      "    x = torch.cat([x1, x2], dim=1)\n",
      "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 32 for tensor number 1 in the list.\n"
     ]
    }
   ],
   "source": [
    "!python src/main.py -d ml-100k --uniform --bs 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retagnn_pyg",
   "language": "python",
   "name": "retagnn_pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
